{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfc6420a",
   "metadata": {},
   "source": [
    "1. Подберите скорость обучения (eta) и количество итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a503a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab630c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae(y, y_pred):\n",
    "    err = np.mean(np.abs(y - y_pred))\n",
    "    return err\n",
    "\n",
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5015c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ 1,  1],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2],\n",
    "              [ 1,  5],\n",
    "              [ 1,  3],\n",
    "              [ 1,  0],\n",
    "              [ 1,  5],\n",
    "              [ 1, 10],\n",
    "              [ 1,  1],\n",
    "              [ 1,  2]])\n",
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5933bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n",
      "Iteration #10: W_new = [ 6.67106886 10.61676385], MSE = 749.71\n",
      "Iteration #20: W_new = [ 9.49320908 10.25731657], MSE = 648.91\n",
      "Iteration #30: W_new = [11.85740092  9.83349244], MSE = 570.46\n",
      "Iteration #40: W_new = [13.86876921  9.46898661], MSE = 508.03\n",
      "Iteration #50: W_new = [15.59085668  9.15672679], MSE = 457.73\n",
      "Iteration #60: W_new = [17.07337653  8.88789585], MSE = 416.77\n",
      "Iteration #70: W_new = [18.35601294  8.65530964], MSE = 383.06\n",
      "Iteration #80: W_new = [19.47073522  8.45317196], MSE = 355.08\n",
      "Iteration #90: W_new = [20.44350656  8.27677488], MSE = 331.65\n",
      "Iteration #100: W_new = [21.29557245  8.12226587], MSE = 311.9\n",
      "Iteration #110: W_new = [22.044442    7.98646992], MSE = 295.12\n",
      "Iteration #120: W_new = [22.7046421   7.86675281], MSE = 280.78\n",
      "Iteration #130: W_new = [23.2883015   7.76091518], MSE = 268.46\n",
      "Iteration #140: W_new = [23.80560705  7.66710979], MSE = 257.81\n",
      "Iteration #150: W_new = [24.26516249  7.5837765 ], MSE = 248.58\n",
      "Iteration #160: W_new = [24.67427278  7.50959066], MSE = 240.53\n",
      "Iteration #170: W_new = [25.03917079  7.44342203], MSE = 233.49\n",
      "Iteration #180: W_new = [25.36519943  7.38430176], MSE = 227.31\n",
      "Iteration #190: W_new = [25.65695861  7.33139573], MSE = 221.86\n",
      "Iteration #200: W_new = [25.91842478  7.28398287], MSE = 217.05\n",
      "Iteration #210: W_new = [26.15304857  7.24143747], MSE = 212.8\n",
      "Iteration #220: W_new = [26.36383499  7.2032146 ], MSE = 209.02\n",
      "Iteration #230: W_new = [26.55340974  7.16883814], MSE = 205.65\n",
      "Iteration #240: W_new = [26.72407419  7.13789077], MSE = 202.66\n",
      "Iteration #250: W_new = [26.87785132  7.11000566], MSE = 199.98\n",
      "Iteration #260: W_new = [27.01652415  7.08485948], MSE = 197.59\n",
      "Iteration #270: W_new = [27.14166815  7.06216655], MSE = 195.44\n",
      "Iteration #280: W_new = [27.25467861  7.04167384], MSE = 193.52\n",
      "Iteration #290: W_new = [27.35679393  7.02315681], MSE = 191.79\n",
      "Iteration #300: W_new = [27.44911541  7.00641573], MSE = 190.24\n",
      "Iteration #310: W_new = [27.53262425  6.99127269], MSE = 188.84\n",
      "Iteration #320: W_new = [27.60819612  6.97756889], MSE = 187.58\n",
      "Iteration #330: W_new = [27.67661373  6.96516242], MSE = 186.45\n",
      "Iteration #340: W_new = [27.73857771  6.9539262 ], MSE = 185.42\n",
      "Iteration #350: W_new = [27.79471602  6.94374639], MSE = 184.5\n",
      "Iteration #360: W_new = [27.84559223  6.93452077], MSE = 183.66\n",
      "Iteration #370: W_new = [27.89171262  6.92615755], MSE = 182.91\n",
      "Iteration #380: W_new = [27.93353252  6.91857415], MSE = 182.23\n",
      "Iteration #390: W_new = [27.9714618   6.91169626], MSE = 181.61\n",
      "Iteration #400: W_new = [28.00586973  6.90545692], MSE = 181.05\n",
      "Iteration #410: W_new = [28.03708926  6.89979574], MSE = 180.54\n",
      "Iteration #420: W_new = [28.06542083  6.89465824], MSE = 180.08\n",
      "Iteration #430: W_new = [28.0911357   6.88999525], MSE = 179.67\n",
      "Iteration #440: W_new = [28.11447893  6.88576231], MSE = 179.29\n",
      "Iteration #450: W_new = [28.13567205  6.88191927], MSE = 178.95\n",
      "Iteration #460: W_new = [28.15491542  6.87842978], MSE = 178.64\n",
      "Iteration #470: W_new = [28.17239031  6.87526098], MSE = 178.36\n",
      "Iteration #480: W_new = [28.18826083  6.8723831 ], MSE = 178.1\n",
      "Iteration #490: W_new = [28.20267557  6.86976921], MSE = 177.87\n",
      "Iteration #500: W_new = [28.21576915  6.86739489], MSE = 177.66\n",
      "Iteration #510: W_new = [28.22766353  6.86523803], MSE = 177.47\n",
      "Iteration #520: W_new = [28.23846929  6.86327857], MSE = 177.3\n",
      "Iteration #530: W_new = [28.24828665  6.86149835], MSE = 177.14\n",
      "Iteration #540: W_new = [28.25720653  6.85988086], MSE = 177.0\n",
      "Iteration #550: W_new = [28.26531139  6.85841117], MSE = 176.87\n",
      "Iteration #560: W_new = [28.27267604  6.85707571], MSE = 176.75\n",
      "Iteration #570: W_new = [28.27936835  6.85586216], MSE = 176.64\n",
      "Iteration #580: W_new = [28.28544995  6.85475935], MSE = 176.55\n",
      "Iteration #590: W_new = [28.29097675  6.85375715], MSE = 176.46\n",
      "Iteration #600: W_new = [28.29599953  6.85284635], MSE = 176.38\n",
      "Iteration #610: W_new = [28.30056439  6.85201858], MSE = 176.31\n",
      "Iteration #620: W_new = [28.30471317  6.85126627], MSE = 176.24\n",
      "Iteration #630: W_new = [28.30848389  6.8505825 ], MSE = 176.18\n",
      "Iteration #640: W_new = [28.31191108  6.84996104], MSE = 176.13\n",
      "Iteration #650: W_new = [28.3150261   6.84939618], MSE = 176.08\n",
      "Iteration #660: W_new = [28.31785743  6.84888276], MSE = 176.03\n",
      "Iteration #670: W_new = [28.32043095  6.84841609], MSE = 175.99\n",
      "Iteration #680: W_new = [28.32277016  6.84799191], MSE = 175.95\n",
      "Iteration #690: W_new = [28.32489644  6.84760634], MSE = 175.92\n",
      "Iteration #700: W_new = [28.32682918  6.84725587], MSE = 175.89\n",
      "Iteration #710: W_new = [28.32858603  6.84693729], MSE = 175.86\n",
      "Iteration #720: W_new = [28.330183    6.84664771], MSE = 175.83\n",
      "Iteration #730: W_new = [28.33163466  6.84638447], MSE = 175.81\n",
      "Iteration #740: W_new = [28.33295423  6.84614518], MSE = 175.79\n",
      "Iteration #750: W_new = [28.33415376  6.84592767], MSE = 175.77\n",
      "Iteration #760: W_new = [28.33524417  6.84572994], MSE = 175.75\n",
      "Iteration #770: W_new = [28.33623538  6.8455502 ], MSE = 175.74\n",
      "Iteration #780: W_new = [28.33713643  6.84538681], MSE = 175.72\n",
      "Iteration #790: W_new = [28.33795553  6.84523828], MSE = 175.71\n",
      "Iteration #800: W_new = [28.33870013  6.84510326], MSE = 175.7\n",
      "Iteration #810: W_new = [28.33937701  6.84498051], MSE = 175.69\n",
      "Iteration #820: W_new = [28.33999233  6.84486894], MSE = 175.68\n",
      "Iteration #830: W_new = [28.34055169  6.8447675 ], MSE = 175.67\n",
      "Iteration #840: W_new = [28.34106018  6.8446753 ], MSE = 175.66\n",
      "Iteration #850: W_new = [28.34152244  6.84459147], MSE = 175.65\n",
      "Iteration #860: W_new = [28.34194266  6.84451527], MSE = 175.65\n",
      "Iteration #870: W_new = [28.34232467  6.844446  ], MSE = 175.64\n",
      "Iteration #880: W_new = [28.34267194  6.84438303], MSE = 175.64\n",
      "Iteration #890: W_new = [28.34298764  6.84432578], MSE = 175.63\n",
      "Iteration #900: W_new = [28.34327463  6.84427374], MSE = 175.63\n",
      "Iteration #910: W_new = [28.34353553  6.84422643], MSE = 175.62\n",
      "Iteration #920: W_new = [28.3437727   6.84418342], MSE = 175.62\n",
      "Iteration #930: W_new = [28.34398832  6.84414432], MSE = 175.61\n",
      "Iteration #940: W_new = [28.34418432  6.84410878], MSE = 175.61\n",
      "Iteration #950: W_new = [28.34436251  6.84407647], MSE = 175.61\n",
      "Iteration #960: W_new = [28.3445245  6.8440471], MSE = 175.61\n",
      "Iteration #970: W_new = [28.34467176  6.84402039], MSE = 175.6\n",
      "Iteration #980: W_new = [28.34480563  6.84399612], MSE = 175.6\n",
      "Iteration #990: W_new = [28.34492733  6.84397405], MSE = 175.6\n",
      "Iteration #1000: W_new = [28.34503796  6.84395399], MSE = 175.6\n",
      "Iteration #1010: W_new = [28.34513854  6.84393575], MSE = 175.6\n",
      "Iteration #1020: W_new = [28.34522997  6.84391917], MSE = 175.6\n",
      "Iteration #1030: W_new = [28.3453131  6.8439041], MSE = 175.59\n",
      "Iteration #1040: W_new = [28.34538866  6.84389039], MSE = 175.59\n",
      "Iteration #1050: W_new = [28.34545735  6.84387794], MSE = 175.59\n",
      "Iteration #1060: W_new = [28.3455198   6.84386661], MSE = 175.59\n",
      "Iteration #1070: W_new = [28.34557657  6.84385632], MSE = 175.59\n",
      "Iteration #1080: W_new = [28.34562818  6.84384696], MSE = 175.59\n",
      "Iteration #1090: W_new = [28.3456751   6.84383845], MSE = 175.59\n",
      "Iteration #1100: W_new = [28.34571776  6.84383072], MSE = 175.59\n",
      "Iteration #1110: W_new = [28.34575653  6.84382369], MSE = 175.59\n",
      "Iteration #1120: W_new = [28.34579178  6.84381729], MSE = 175.59\n",
      "Iteration #1130: W_new = [28.34582383  6.84381148], MSE = 175.59\n",
      "Iteration #1140: W_new = [28.34585296  6.8438062 ], MSE = 175.59\n",
      "Iteration #1150: W_new = [28.34587944  6.8438014 ], MSE = 175.58\n",
      "Iteration #1160: W_new = [28.34590352  6.84379703], MSE = 175.58\n",
      "Iteration #1170: W_new = [28.34592541  6.84379306], MSE = 175.58\n",
      "Iteration #1180: W_new = [28.3459453   6.84378945], MSE = 175.58\n",
      "Iteration #1190: W_new = [28.34596339  6.84378617], MSE = 175.58\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "\n",
    "eta = 1e-2    # нет ИЗМЕНЕНИЙ: оставила 0,01, так как значения MSE меняются плавно, не перескакивают\n",
    "n_iter = 1200 # ИЗМЕНЕНИЯ: (было 100) на итерации 1150 значения MSE перестают значимо меняться,\n",
    "              #             оставила ещё 50 итераций, чтобы убедиться в этом\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    for k in range(W.shape[0]):\n",
    "        W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "    if i % 10 == 0:\n",
    "        eta /= 1.1\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc345c0",
   "metadata": {},
   "source": [
    "2*. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b70b31b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [4.77 4.27], MSE = 3047.75\n",
      "Iteration #10: W_new = [10.10145365  9.60145365], MSE = 624.54\n",
      "Iteration #20: W_new = [10.30592861  9.80592861], MSE = 613.07\n",
      "Iteration #30: W_new = [10.3429761  9.8429761], MSE = 611.47\n",
      "Iteration #40: W_new = [10.35382943  9.85382943], MSE = 611.02\n",
      "Iteration #50: W_new = [10.35760203  9.85760203], MSE = 610.87\n",
      "Iteration #60: W_new = [10.35900004  9.85900004], MSE = 610.82\n",
      "Iteration #70: W_new = [10.35953089  9.85953089], MSE = 610.8\n",
      "Iteration #80: W_new = [10.35973435  9.85973435], MSE = 610.79\n",
      "Iteration #90: W_new = [10.35981262  9.85981262], MSE = 610.79\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[0]\n",
    "\n",
    "eta = 1e-2 \n",
    "n_iter = 100\n",
    "\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(n_iter):\n",
    "    y_pred = np.dot(X, W)\n",
    "    err = calc_mse(y, y_pred)\n",
    "#     for k in range(W.shape[0]):\n",
    "#         W[k] -= eta * (1/n * 2 * X[:, k] @ (y_pred - y))\n",
    "    # ИЗМЕНЕНИЯ\n",
    "    # я уточнила столбец в матрице X, чтобы удовлетворить условию уммножения матрицы на вектор (количесво столбцов равно количеству строк)    \n",
    "    W -= eta * (1/n * 2 * np.dot(X[:, 1], y_pred - y))\n",
    "    # ИЗМЕНЕНИЯ\n",
    "    # добавила строку с изменением шага(eta) на каждой интерации (i) в цикле for\n",
    "    eta /= 1.1\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70435c49",
   "metadata": {},
   "source": [
    "3*. Вместо того, чтобы задавать количество итераций, задайте другое условие останова алгоритма - когда веса перестают изменяться меньше определенного порога $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "904a4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# следующий код я составила заново, опираясь на материалы урока, используя данные из предыдущих заданий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edf28ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 1,  1],\n",
       "       [ 1,  2],\n",
       "       [ 1,  5],\n",
       "       [ 1,  3],\n",
       "       [ 1,  0],\n",
       "       [ 1,  5],\n",
       "       [ 1, 10],\n",
       "       [ 1,  1],\n",
       "       [ 1,  2]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "446f3e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iter 10: mse_error - 752.0184356756685, weights: [ 6.64172205 10.62940003]\n",
      "Iter 20: mse_error - 632.7150870310963, weights: [10.02900674 10.16329008]\n",
      "Iter 30: mse_error - 534.1424546924877, weights: [13.09636548  9.60903915]\n",
      "Iter 40: mse_error - 452.07375384905697, weights: [15.89487851  9.10159809]\n",
      "Iter 50: mse_error - 383.7456343612788, weights: [18.44838865  8.63855875]\n",
      "Iter 60: mse_error - 326.857541015558, weights: [20.77834901  8.21605636]\n",
      "Iter 70: mse_error - 279.4940955004128, weights: [22.90433054  7.83054239]\n",
      "Iter 80: mse_error - 240.06060706491303, weights: [24.84419078  7.47877865]\n",
      "Iter 90: mse_error - 207.22938050865514, weights: [26.61422391  7.15781043]\n",
      "Iter 100: mse_error - 179.89501370640295, weights: [28.22929764  6.86494171]\n",
      "Iter 110: mse_error - 157.13717956944907, weights: [29.70297804  6.59771249]\n",
      "Iter 120: mse_error - 138.189639340991, weights: [31.04764353  6.35387814]\n",
      "Iter 130: mse_error - 122.41444392702674, weights: [32.27458888  6.13139052]\n",
      "Iter 140: mse_error - 109.28045464144164, weights: [33.39412     5.92838081]\n",
      "Iter 150: mse_error - 98.34546017530852, weights: [34.41564059  5.7431438 ]\n",
      "Iter 160: mse_error - 89.2412876825235, weights: [35.34773109  5.57412356]\n",
      "Iter 170: mse_error - 81.66140668348939, weights: [36.19822075  5.41990037]\n",
      "Iter 180: mse_error - 75.35060841983059, weights: [36.9742534   5.27917882]\n",
      "Iter 190: mse_error - 70.09641317195339, weights: [37.68234745  5.15077688]\n",
      "Iter 200: mse_error - 65.72191623045093, weights: [38.32845066  5.03361602]\n",
      "Iter 210: mse_error - 62.07983165071513, weights: [38.91799009  4.92671213]\n",
      "Iter 220: mse_error - 59.0475332485603, weights: [39.45591767  4.82916726]\n",
      "Iter 230: mse_error - 56.52292587099686, weights: [39.94675181  4.74016206]\n",
      "Iter 240: mse_error - 54.42100793102158, weights: [40.39461537  4.65894891]\n",
      "Iter 250: mse_error - 52.671009469615726, weights: [40.80327023  4.58484565]\n",
      "Iter 260: mse_error - 51.21400938570243, weights: [41.17614898  4.51722984]\n",
      "Iter 270: mse_error - 50.000951608029894, weights: [41.51638367  4.45553352]\n",
      "Iter 280: mse_error - 48.99099341501478, weights: [41.82683215  4.39923848]\n",
      "Iter 290: mse_error - 48.1501302917468, weights: [42.11010209  4.34787184]\n",
      "Iter 300: mse_error - 47.450051024147385, weights: [42.36857287  4.30100215]\n",
      "Iter 310: mse_error - 46.867184482185465, weights: [42.60441555  4.25823571]\n",
      "Iter 320: mse_error - 46.38190599807382, weights: [42.81961114  4.21921331]\n",
      "Iter 330: mse_error - 45.977876618811365, weights: [43.0159672   4.18360717]\n",
      "Iter 340: mse_error - 45.64149298621326, weights: [43.19513307  4.1511182 ]\n",
      "Iter 350: mse_error - 45.36142932231222, weights: [43.35861367  4.12147351]\n",
      "Iter 360: mse_error - 45.12825609913287, weights: [43.50778219  4.0944241 ]\n",
      "Iter 370: mse_error - 44.93412255374351, weights: [43.6438916   4.06974276]\n",
      "Iter 380: mse_error - 44.77249235911156, weights: [43.76808516  4.04722217]\n",
      "Iter 390: mse_error - 44.63792355100384, weights: [43.88140607  4.02667317]\n",
      "Iter 400: mse_error - 44.525885301240166, weights: [43.98480618  4.00792316]\n",
      "Iter 410: mse_error - 44.43260536819608, weights: [44.07915402  3.99081463]\n",
      "Iter 420: mse_error - 44.35494308833129, weights: [44.16524207  3.97520389]\n",
      "Iter 430: mse_error - 44.29028363246583, weights: [44.24379346  3.96095981]\n",
      "Iter 440: mse_error - 44.23644996649443, weights: [44.31546799  3.94796274]\n",
      "Iter 450: mse_error - 44.191629552324095, weights: [44.38086769  3.93610351]\n",
      "Iter 460: mse_error - 44.15431332111165, weights: [44.44054191  3.92528251]\n",
      "Iter 470: mse_error - 44.1232448640776, weights: [44.49499188  3.91540885]\n",
      "Iter 480: mse_error - 44.09737813018957, weights: [44.54467498  3.90639958]\n",
      "Iter 490: mse_error - 44.0758422064293, weights: [44.59000851  3.89817905]\n",
      "Iter 500: mse_error - 44.05791199482176, weights: [44.63137328  3.89067818]\n",
      "Iter 510: mse_error - 44.04298379894449, weights: [44.66911672  3.88383399]\n",
      "Iter 520: mse_error - 44.030554997933805, weights: [44.70355587  3.87758898]\n",
      "Iter 530: mse_error - 44.02020712362711, weights: [44.73498001  3.8718907 ]\n",
      "Iter 540: mse_error - 44.01159177106213, weights: [44.76365309  3.86669128]\n",
      "Iter 550: mse_error - 44.00441886794995, weights: [44.78981596  3.86194705]\n",
      "Iter 560: mse_error - 43.99844690816438, weights: [44.81368837  3.85761815]\n",
      "Iter 570: mse_error - 43.99347482041654, weights: [44.83547085  3.85366824]\n",
      "Iter 580: mse_error - 43.98933519833936, weights: [44.85534635  3.85006412]\n",
      "Iter 590: mse_error - 43.98588866404416, weights: [44.87348184  3.84677553]\n",
      "Iter 600: mse_error - 43.98301917537428, weights: [44.89002963  3.84377484]\n",
      "Iter 610: mse_error - 43.98063011885507, weights: [44.90512873  3.84103685]\n",
      "Iter 620: mse_error - 43.9786410567926, weights: [44.91890596  3.83853856]\n",
      "Iter 630: mse_error - 43.97698501899838, weights: [44.93147705  3.83625899]\n",
      "Iter 640: mse_error - 43.975606247954666, weights: [44.9429476   3.83417899]\n",
      "Iter 650: mse_error - 43.97445832150176, weights: [44.95341394  3.83228108]\n",
      "Iter 660: mse_error - 43.97350258983963, weights: [44.96296399  3.83054932]\n",
      "Iter 670: mse_error - 43.97270687421896, weights: [44.97167798  3.82896917]\n",
      "Iter 680: mse_error - 43.9720443835073, weights: [44.97962909  3.82752736]\n",
      "Iter 690: mse_error - 43.97149281215238, weights: [44.98688411  3.82621178]\n",
      "Iter 700: mse_error - 43.97103358917125, weights: [44.99350398  3.82501136]\n",
      "Iter 710: mse_error - 43.970651252879655, weights: [44.99954431  3.82391604]\n",
      "Iter 720: mse_error - 43.970332930308956, weights: [45.00505583  3.82291661]\n",
      "Iter 730: mse_error - 43.97006790378326, weights: [45.01008484  3.82200468]\n",
      "Iter 740: mse_error - 43.96984725006344, weights: [45.01467358  3.82117258]\n",
      "Iter 750: mse_error - 43.96966353990861, weights: [45.0188606   3.82041333]\n",
      "Iter 760: mse_error - 43.969510587939276, weights: [45.02268105  3.81972055]\n",
      "Iter 770: mse_error - 43.96938324438038, weights: [45.02616704  3.81908842]\n",
      "Iter 780: mse_error - 43.9692772216723, weights: [45.02934785  3.81851163]\n",
      "Iter 790: mse_error - 43.96918895011209, weights: [45.03225019  3.81798534]\n",
      "Iter 800: mse_error - 43.969115457664245, weights: [45.03489844  3.81750512]\n",
      "Iter 810: mse_error - 43.96905426989465, weights: [45.03731485  3.81706694]\n",
      "Iter 820: mse_error - 43.96900332665816, weights: [45.03951971  3.81666712]\n",
      "Iter 830: mse_error - 43.96896091273526, weights: [45.04153154  3.81630231]\n",
      "Iter 840: mse_error - 43.96892560008182, weights: [45.04336725  3.81596943]\n",
      "Iter 850: mse_error - 43.96889619974793, weights: [45.04504225  3.81566569]\n",
      "Iter 860: mse_error - 43.968871721847016, weights: [45.0465706   3.81538855]\n",
      "Iter 870: mse_error - 43.968851342227, weights: [45.04796516  3.81513567]\n",
      "Iter 880: mse_error - 43.96883437472174, weights: [45.04923763  3.81490493]\n",
      "Iter 890: mse_error - 43.968820248048424, weights: [45.0503987   3.81469438]\n",
      "Iter 900: mse_error - 43.968808486572826, weights: [45.05145812  3.81450228]\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(y)\n",
    "W = np.array([1, 0.5])\n",
    "eta = 1e-2\n",
    "\n",
    "weight_dist = np.inf\n",
    "min_weight_dist = 1e-4\n",
    "iter_num = 0\n",
    "\n",
    "print(f'Number of objects = {X.shape[0]} \\\n",
    "       \\nLearning rate = {eta} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "while weight_dist > min_weight_dist:\n",
    "    Y_pred = np.dot(X, W)\n",
    "    dQ = 2 / X.shape[0] * np.dot(X.T, Y_pred - Y)\n",
    "    W_new = W - eta * dQ \n",
    "    weight_dist = np.linalg.norm(W - W_new, ord=2)\n",
    "    mse_err = calc_mse(Y, Y_pred)\n",
    "   \n",
    "    W = W_new\n",
    "    iter_num +=1\n",
    "    \n",
    "    if iter_num % 10 == 0:         \n",
    "        print(f'Iter {iter_num}: mse_error - {mse_err}, weights: {W}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558fc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
